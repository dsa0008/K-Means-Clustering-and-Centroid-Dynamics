{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsa0008/K-Means-Clustering-and-Centroid-Dynamics/blob/main/Data_mining_class_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD-qHJbsUF0n",
        "outputId": "62d6a5c9-3789-4a09-c109-4ae37bd26e33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Author**: Ronny Kohavi and Barry Becker  \n",
            "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Adult) - 1996  \n",
            "**Please cite**: Ron Kohavi, \"Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid\", Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996  \n",
            "\n",
            "Prediction task is to determine whether a person makes over 50K a year. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
            "\n",
            "This is the original version from the UCI repository, with training and test sets merged.\n",
            "\n",
            "### Variable description\n",
            "\n",
            "Variables are all self-explanatory except __fnlwgt__. This is a proxy for the demographic background of the people: \"People with similar demographic characteristics should have similar weights\". This similarity-statement is not transferable across the 51 different states.\n",
            "\n",
            "Description from the donor of the database: \n",
            "\n",
            "The weights on the CPS files are controlled to independent estimates of the civilian noninstitutional population of the US.  These are prepared monthly for us by Population Division here at the Census Bureau. We use 3 sets of controls. These are:\n",
            "1.  A single cell estimate of the population 16+ for each state.\n",
            "2.  Controls for Hispanic Origin by age and sex.\n",
            "3.  Controls by Race, age and sex.\n",
            "\n",
            "We use all three sets of controls in our weighting program and \"rake\" through them 6 times so that by the end we come back to all the controls we used. The term estimate refers to population totals derived from CPS by creating \"weighted tallies\" of any specified socio-economic characteristics of the population. People with similar demographic characteristics should have similar weights. There is one important caveat to remember about this statement. That is that since the CPS sample is actually a collection of 51 state samples, each with its own probability of selection, the statement only applies within state.\n",
            "\n",
            "\n",
            "### Relevant papers  \n",
            "\n",
            "Ronny Kohavi and Barry Becker. Data Mining and Visualization, Silicon Graphics.  \n",
            "e-mail: ronnyk '@' live.com for questions.\n",
            "\n",
            "Downloaded from openml.org.\n"
          ]
        }
      ],
      "source": [
        " from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Fetch the Adult dataset\n",
        "adult = fetch_openml(name='adult', version=2)\n",
        "\n",
        "# Data and target\n",
        "X = adult.data\n",
        "y = adult.target\n",
        "\n",
        "# Print some information\n",
        "print(adult.DESCR)  # Dataset description\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "bhe7srMZp34J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2G9ZfjkVmkw",
        "outputId": "f36a64b6-3a2f-4790-b62e-52a9ffee5608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    age  workclass    fnlwgt     education  education-num      marital-status  \\\n",
            "0  25.0    Private  226802.0          11th            7.0       Never-married   \n",
            "1  38.0    Private   89814.0       HS-grad            9.0  Married-civ-spouse   \n",
            "2  28.0  Local-gov  336951.0    Assoc-acdm           12.0  Married-civ-spouse   \n",
            "3  44.0    Private  160323.0  Some-college           10.0  Married-civ-spouse   \n",
            "4  18.0        NaN  103497.0  Some-college           10.0       Never-married   \n",
            "\n",
            "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
            "0  Machine-op-inspct    Own-child  Black    Male           0.0           0.0   \n",
            "1    Farming-fishing      Husband  White    Male           0.0           0.0   \n",
            "2    Protective-serv      Husband  White    Male           0.0           0.0   \n",
            "3  Machine-op-inspct      Husband  Black    Male        7688.0           0.0   \n",
            "4                NaN    Own-child  White  Female           0.0           0.0   \n",
            "\n",
            "   hours-per-week native-country  \n",
            "0            40.0  United-States  \n",
            "1            50.0  United-States  \n",
            "2            40.0  United-States  \n",
            "3            40.0  United-States  \n",
            "4            30.0  United-States  \n",
            "0    <=50K\n",
            "1    <=50K\n",
            "2     >50K\n",
            "3     >50K\n",
            "4    <=50K\n",
            "Name: class, dtype: category\n",
            "Categories (2, object): ['<=50K', '>50K']\n",
            "    age  workclass    fnlwgt     education  education-num      marital-status  \\\n",
            "0  25.0    Private  226802.0          11th            7.0       Never-married   \n",
            "1  38.0    Private   89814.0       HS-grad            9.0  Married-civ-spouse   \n",
            "2  28.0  Local-gov  336951.0    Assoc-acdm           12.0  Married-civ-spouse   \n",
            "3  44.0    Private  160323.0  Some-college           10.0  Married-civ-spouse   \n",
            "4  18.0        NaN  103497.0  Some-college           10.0       Never-married   \n",
            "\n",
            "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
            "0  Machine-op-inspct    Own-child  Black    Male           0.0           0.0   \n",
            "1    Farming-fishing      Husband  White    Male           0.0           0.0   \n",
            "2    Protective-serv      Husband  White    Male           0.0           0.0   \n",
            "3  Machine-op-inspct      Husband  Black    Male        7688.0           0.0   \n",
            "4                NaN    Own-child  White  Female           0.0           0.0   \n",
            "\n",
            "   hours-per-week native-country income  \n",
            "0            40.0  United-States  <=50K  \n",
            "1            50.0  United-States  <=50K  \n",
            "2            40.0  United-States   >50K  \n",
            "3            40.0  United-States   >50K  \n",
            "4            30.0  United-States  <=50K  \n"
          ]
        }
      ],
      "source": [
        "#Convert this in pandas framework to be used for further process\n",
        "import pandas as pd\n",
        "# Data and target\n",
        "X = pd.DataFrame(adult.data, columns=adult.feature_names)\n",
        "y = pd.Series(adult.target)\n",
        "# Display the first few rows of the dataset\n",
        "print(X.head())\n",
        "\n",
        "# Display the first few rows of the target variable\n",
        "print(y.head())\n",
        "\n",
        "# Optionally, if you want to combine the features and target into a single DataFrame:\n",
        "adult_df = X.copy()\n",
        "adult_df['income'] = y  # Assuming 'income' is the target variable you're interested in\n",
        "\n",
        "# Display the first few rows of the combined DataFrame\n",
        "print(adult_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2faygwe_0RV",
        "outputId": "e6f89260-9512-46b3-8a00-6d41d42de780"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayesian Classifier Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.91      0.87      0.89      6842\n",
            "        >50K       0.64      0.74      0.69      2203\n",
            "\n",
            "    accuracy                           0.84      9045\n",
            "   macro avg       0.78      0.80      0.79      9045\n",
            "weighted avg       0.85      0.84      0.84      9045\n",
            "\n",
            "Decision Tree Classifier Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.89      0.92      0.90      6842\n",
            "        >50K       0.71      0.63      0.67      2203\n",
            "\n",
            "    accuracy                           0.85      9045\n",
            "   macro avg       0.80      0.77      0.79      9045\n",
            "weighted avg       0.84      0.85      0.84      9045\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Fetch the Adult dataset\n",
        "adult = fetch_openml(name='adult', version=2)\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "X = pd.DataFrame(adult.data, columns=adult.feature_names)\n",
        "y = pd.Series(adult.target).apply(lambda x: \">50K\" if x.strip() == \">50K\" else \"<=50K\")\n",
        "\n",
        "# Replace '?' with numpy.nan and drop rows with any NaN values\n",
        "X.replace('?', np.nan, inplace=True)\n",
        "X.dropna(inplace=True)\n",
        "y = y[X.index].copy()  # Adjust 'y' to match the cleaned 'X'\n",
        "\n",
        "# Assume all features are categorical for this example\n",
        "categorical_features = X.columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline for categorical variables\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "    ])\n",
        "\n",
        "# Function to convert a sparse matrix to a dense matrix\n",
        "def to_dense(X):\n",
        "    if isinstance(X, csr_matrix):\n",
        "        return X.toarray()\n",
        "    return X\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Naive Bayesian Classifier pipeline\n",
        "nb_pipeline = make_pipeline(\n",
        "    preprocessor,\n",
        "    FunctionTransformer(to_dense, accept_sparse=True),  # Use the to_dense function here\n",
        "    CategoricalNB()\n",
        ")\n",
        "\n",
        "# Fit and evaluate Naive Bayesian Classifier\n",
        "nb_pipeline.fit(X_train, y_train)\n",
        "y_pred_nb = nb_pipeline.predict(X_test)\n",
        "\n",
        "print(\"Naive Bayesian Classifier Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "# Decision Tree Classifier pipeline (unchanged)\n",
        "dt_pipeline = make_pipeline(preprocessor, DecisionTreeClassifier(random_state=42))\n",
        "dt_pipeline.fit(X_train, y_train)\n",
        "y_pred_dt = dt_pipeline.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree Classifier Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_dt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRs1IlVfC-H7",
        "outputId": "79016695-2662-42f8-a8fb-8d9263e9da49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XXLXCgiZa0p"
      },
      "source": [
        "Cleaning the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GYfA0N7CFWJ"
      },
      "source": [
        "2. Remove records with unknown (?) values from both train and test data sets. For each multi-domain categorical attribute, use one-hot encoding to transform data; for each numerical attribute, use the mean value to transform into binary attribute. (2 points)\n",
        "\n",
        "  Build k-means clustering algorithm over train data with varied k values (3, 5, 10) based on your chosen distance function and report the centroids of the clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVigbfUXZg4f",
        "outputId": "439432ab-7f38-4f4b-e582-940ae71ec065"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Centroids for k=3:\n",
            "[[ 4.72081218e-01  5.27918782e-01  4.19558686e-02  1.06184606e-01\n",
            "   6.43944888e-01  5.38692634e-02  8.89878794e-02  6.49539003e-02\n",
            "   1.03594737e-04  5.79198177e-01  4.20801823e-01 -1.36002321e-15\n",
            "   1.92901251e-15  1.03594737e-04  3.89445420e-16 -7.35522754e-16\n",
            "   1.17267307e-15 -7.51135265e-16  9.29244794e-02  1.23381332e-01\n",
            "   5.21806692e-01  3.87444318e-02  2.44804177e-14  1.66994717e-01\n",
            "  -7.17741838e-17  5.60447529e-02  2.07334150e-14  1.03594737e-04\n",
            "   9.99896405e-01  1.25971201e-01  6.21568424e-04  5.47601782e-01\n",
            "   1.00486895e-02  2.79291412e-01  1.92686212e-02  1.71967264e-02\n",
            "   8.55692531e-02  2.07189475e-04  6.25712214e-02  2.28840775e-01\n",
            "   1.63679685e-02  1.02558790e-02  1.59535896e-02  3.28395318e-02\n",
            "   1.03594737e-03  3.44970475e-01  2.05117580e-02  1.21205843e-01\n",
            "   4.57888739e-02  1.38816948e-02  4.84616181e-01  2.91619186e-01\n",
            "   1.30529369e-02  7.50025899e-02  7.74888636e-02  5.82202424e-02\n",
            "   4.97254739e-03  4.67212266e-02  5.67699161e-02  4.55816845e-03\n",
            "   8.86978142e-01  2.89961670e-01  7.10038330e-01  8.69574226e-01\n",
            "   1.30425774e-01  9.30280742e-01  6.97192583e-02  5.79094582e-01\n",
            "   4.20905418e-01  3.10784212e-04  4.66176318e-03  4.14378950e-03\n",
            "   1.76111054e-03  3.31503160e-03  6.21568424e-04  6.21568424e-04\n",
            "   1.24313685e-03  4.55816845e-03  1.86470527e-03  6.52646846e-03\n",
            "   1.03594737e-03  2.07189475e-04  7.25163162e-04  2.52754631e-18\n",
            "   2.07189475e-04  1.13954211e-03  6.21568424e-04  7.66601057e-03\n",
            "   3.10784212e-03  8.28757899e-04  2.17548949e-03  1.86470527e-03\n",
            "   3.21143686e-03  4.14378950e-04  4.66176318e-03  5.17973687e-04\n",
            "   4.14378950e-04  5.17973687e-04  1.01522843e-02  1.96830001e-03\n",
            "   5.17973687e-04  1.76111054e-03  3.10784212e-04  3.52222107e-03\n",
            "   3.72941055e-03  8.28757899e-04  2.07189475e-04  9.15570289e-01\n",
            "   1.76111054e-03  7.25163162e-04]\n",
            " [ 4.07193159e-01  5.92806841e-01  2.76659960e-02  5.75955734e-02\n",
            "   7.06111670e-01  4.85412475e-02  1.32796781e-01  2.67857143e-02\n",
            "   5.03018109e-04  5.71051308e-01  4.28948692e-01  3.81036217e-02\n",
            "   3.69718310e-02  1.24496982e-02  8.29979879e-03  1.62223340e-02\n",
            "   3.79778672e-02  2.46478873e-02 -1.31838984e-16 -4.28823643e-15\n",
            "  -3.91353616e-15  7.02563008e-16  5.20497988e-01  4.88498131e-15\n",
            "   1.76056338e-03 -1.21777588e-15  3.03068410e-01  1.00000000e+00\n",
            "  -1.39888101e-14  2.26358149e-03  7.54527163e-04  9.92454728e-01\n",
            "   7.54527163e-04  2.60902411e-15  1.88631791e-03  1.88631791e-03\n",
            "   4.89185111e-02  2.51509054e-04  2.67102616e-01  1.14310865e-01\n",
            "   5.83501006e-02  4.84154930e-02  9.95975855e-02  5.44517103e-02\n",
            "   1.25754527e-04  3.26961771e-02  3.18158954e-02  1.10789738e-01\n",
            "   2.10010060e-02  1.12173038e-01  9.78998994e-01  2.89235412e-03\n",
            "   7.16800805e-03  2.89235412e-03  3.26961771e-03  4.77867203e-03\n",
            "   9.93460765e-03  1.86116700e-02  5.97334004e-02  7.41951710e-03\n",
            "   9.04300805e-01  5.03018109e-03  9.94969819e-01  9.06564386e-01\n",
            "   9.34356137e-02  9.48440644e-01  5.15593561e-02  6.23113682e-01\n",
            "   3.76886318e-01  1.13179074e-03  2.89235412e-03  1.63480885e-03\n",
            "   1.25754527e-03  3.64688129e-03  1.76056338e-03  1.00603622e-03\n",
            "   2.76659960e-03  1.25754527e-03  2.51509054e-04  3.39537223e-03\n",
            "   1.13179074e-03  1.63480885e-03  8.80281690e-04  2.05998413e-18\n",
            "  -3.70255042e-17  2.51509054e-04  3.77263581e-04  1.00603622e-03\n",
            "   5.03018109e-04  6.28772636e-04  3.64688129e-03  1.76056338e-03\n",
            "   7.54527163e-04  6.28772636e-04  3.11871227e-02  1.00603622e-03\n",
            "   2.51509054e-04  7.54527163e-04  4.02414487e-03  2.38933602e-03\n",
            "   1.50905433e-03  2.89235412e-03  2.51509054e-04  1.63480885e-03\n",
            "   5.03018109e-04  3.77263581e-04  8.80281690e-04  9.16121730e-01\n",
            "   1.50905433e-03  5.03018109e-04]\n",
            " [ 6.70064506e-01  3.29935494e-01  2.53245202e-02  4.65079239e-02\n",
            "   8.32603329e-01  1.33789918e-02  4.65079239e-02  3.49605798e-02\n",
            "   7.16731703e-04  5.43521542e-01  4.56478458e-01  4.11722545e-02\n",
            "   6.00461894e-02  2.20594091e-02  6.76913275e-03  1.26622601e-02\n",
            "   2.03073983e-02  2.06259457e-02  8.83969101e-03  9.23787529e-03\n",
            "   5.57457992e-04  7.96368559e-05  4.54009716e-01  1.19455284e-03\n",
            "   2.46874253e-03  7.96368559e-05  3.39890101e-01  9.80011149e-01\n",
            "   1.99888508e-02  2.37317831e-01  7.16731703e-04  7.06378912e-02\n",
            "   2.12630405e-02  5.59847097e-01  5.87719997e-02  5.14454089e-02\n",
            "   1.99569961e-01  3.98184280e-04  1.03687186e-01  6.96026121e-02\n",
            "   2.92267261e-02  6.89655172e-02  8.12295931e-02  1.96065939e-01\n",
            "   1.05120650e-02  3.56773115e-02  1.53699132e-02  1.22083300e-01\n",
            "   2.41299673e-02  4.34817233e-02  1.18793864e-14  3.89264952e-01\n",
            "   5.62236203e-02  2.96169467e-01  1.94154655e-01  6.41873059e-02\n",
            "   1.26622601e-02  2.35725094e-02  1.42868520e-01  1.01935176e-02\n",
            "   8.10703193e-01  5.52918691e-01  4.47081309e-01  9.62729951e-01\n",
            "   3.72700486e-02  9.72604922e-01  2.73950784e-02  8.29816039e-01\n",
            "   1.70183961e-01  4.77821136e-04  3.10583738e-03  1.19455284e-03\n",
            "   2.30946882e-03  2.46874253e-03  3.74293223e-03  1.03527913e-03\n",
            "   5.25603249e-03  2.54837939e-03  5.57457992e-04  3.02620053e-03\n",
            "   7.96368559e-04  3.82256908e-03  2.22983197e-03  7.96368559e-05\n",
            "   7.96368559e-04  4.77821136e-04  3.18547424e-04  1.43346341e-03\n",
            "   6.37094847e-04  8.76005415e-04  1.43346341e-03  3.82256908e-03\n",
            "   1.75201083e-03  6.37094847e-04  2.52448833e-02  1.59273712e-03\n",
            "   6.37094847e-04  1.51310026e-03  4.61893764e-03  1.43346341e-03\n",
            "   1.35382655e-03  5.49494306e-03  4.77821136e-04  1.91128454e-03\n",
            "   1.59273712e-04  4.77821136e-04  7.16731703e-04  9.06347057e-01\n",
            "   2.78728996e-03  3.98184280e-04]]\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Centroids for k=5:\n",
            "[[ 4.11502736e-01  5.88497264e-01  2.78661407e-02  5.78954065e-02\n",
            "   7.10013997e-01  4.74615091e-02  1.29151292e-01  2.71026848e-02\n",
            "   5.08970607e-04  5.69156381e-01  4.30843619e-01  3.79183102e-02\n",
            "   3.74093396e-02  1.23425372e-02  8.39801501e-03  1.62870594e-02\n",
            "   3.79183102e-02  2.45578318e-02 -1.31838984e-16 -4.25354196e-15\n",
            "  -4.30211422e-15  6.81746326e-16  5.19531747e-01  4.87110352e-15\n",
            "   1.78139712e-03 -1.20042865e-15  3.03855452e-01  1.00000000e+00\n",
            "  -1.29340982e-14  1.03805853e-14  7.63455910e-04  9.98727573e-01\n",
            "   1.27242652e-04  1.27242652e-04  1.27242652e-04  1.27242652e-04\n",
            "   4.92429062e-02  2.54485303e-04  2.67591297e-01  1.13373203e-01\n",
            "   5.75136786e-02  4.89884209e-02  1.00139967e-01  5.48415829e-02\n",
            "   1.79543880e-16  3.25741188e-02  3.20651482e-02  1.09810408e-01\n",
            "   2.12495228e-02  1.12355261e-01  9.90584044e-01  3.81727955e-04\n",
            "   6.61661789e-03  2.41761038e-03 -1.00613962e-14  1.61676228e-15\n",
            "   1.00521695e-02  1.87046698e-02  6.01857743e-02  7.38007380e-03\n",
            "   9.03677313e-01  1.27242652e-04  9.99872757e-01  9.07367350e-01\n",
            "   9.26326505e-02  9.48721211e-01  5.12787886e-02  6.29596641e-01\n",
            "   3.70403359e-01  1.14518387e-03  2.54485303e-03  1.65415447e-03\n",
            "   1.27242652e-03  3.69003690e-03  1.52691182e-03  1.01794121e-03\n",
            "   2.79933834e-03  1.14518387e-03  2.54485303e-04  3.43555160e-03\n",
            "   1.14518387e-03  1.65415447e-03  8.90698562e-04  2.03965534e-18\n",
            "  -3.68086638e-17  2.54485303e-04  3.81727955e-04  1.01794121e-03\n",
            "   3.81727955e-04  6.36213259e-04  3.43555160e-03  1.78139712e-03\n",
            "   7.63455910e-04  6.36213259e-04  3.13016923e-02  1.01794121e-03\n",
            "   2.54485303e-04  7.63455910e-04  4.07176486e-03  2.29036773e-03\n",
            "   1.52691182e-03  2.92658099e-03  2.54485303e-04  1.65415447e-03\n",
            "   5.08970607e-04  3.81727955e-04  8.90698562e-04  9.16656063e-01\n",
            "   1.52691182e-03  5.08970607e-04]\n",
            " [ 9.53694718e-01  4.63052821e-02  1.62207126e-02  3.24414252e-02\n",
            "   8.72868432e-01  9.84333842e-03  3.82642451e-02  2.98072924e-02\n",
            "   5.54554277e-04  5.06030778e-01  4.93969222e-01  4.53348121e-02\n",
            "   7.68057674e-02  2.95300153e-02  6.23873562e-03  1.19229170e-02\n",
            "   1.35865798e-02  1.92707611e-02  1.66366283e-03  1.10910855e-03\n",
            "  -7.27196081e-15  5.11743425e-16  4.24095383e-01  2.77277139e-04\n",
            "   2.63413282e-03 -1.08246745e-15  3.67530847e-01  9.96949951e-01\n",
            "   3.05004852e-03  6.83488146e-02  4.15915708e-04  6.93192846e-03\n",
            "   1.24774712e-02  8.84098156e-01  2.63413282e-02  1.38638569e-03\n",
            "   1.48343269e-01  6.93192846e-04  1.28656592e-01  4.22847636e-02\n",
            "   3.77096908e-02  1.00651601e-01  7.66671288e-02  1.98669070e-01\n",
            "   7.07056703e-03  3.28573409e-02  1.78843754e-02  1.36143075e-01\n",
            "   2.16276168e-02  5.07417163e-02  1.13797860e-14  3.75294607e-01\n",
            "   6.82101761e-02  4.72480244e-01  8.38763344e-02  1.38638569e-04\n",
            "   1.16456398e-02  2.53708582e-02  1.27824761e-01  1.13683627e-02\n",
            "   8.23790378e-01  3.63926244e-01  6.36073756e-01  9.74629142e-01\n",
            "   2.53708582e-02  9.74490503e-01  2.55094967e-02  8.27256343e-01\n",
            "   1.72743657e-01  6.93192846e-04  2.35685568e-03  4.15915708e-04\n",
            "   1.94093997e-03  9.70469985e-04  3.60460280e-03  9.70469985e-04\n",
            "   6.65465132e-03  2.21821711e-03  1.38638569e-04  2.49549425e-03\n",
            "   8.31831415e-04  4.99098849e-03  1.52502426e-03  1.38638569e-04\n",
            "   8.31831415e-04  5.54554277e-04  1.38638569e-04  2.07957854e-03\n",
            "   8.31831415e-04  1.10910855e-03  5.54554277e-04  4.29779565e-03\n",
            "   1.80230140e-03  5.54554277e-04  3.29959795e-02  2.07957854e-03\n",
            "   5.54554277e-04  1.24774712e-03  4.57507279e-03  1.10910855e-03\n",
            "   5.54554277e-04  4.15915708e-03  1.38638569e-04  1.66366283e-03\n",
            "   1.38638569e-04  4.15915708e-04  2.77277138e-04  9.03230279e-01\n",
            "   3.74324137e-03  4.15915708e-04]\n",
            " [ 6.07651767e-01  3.92348233e-01  3.92348233e-02  1.22779621e-01\n",
            "   6.81631856e-01  2.47901620e-02  6.51961741e-02  6.63673629e-02\n",
            "  -8.56519716e-18  5.72125708e-01  4.27874292e-01 -1.17961196e-15\n",
            "  -9.85322934e-16 -3.08780779e-16  1.77809156e-16  2.46330734e-16\n",
            "   3.12250226e-16 -4.90926744e-16  1.20046848e-01  1.37419481e-01\n",
            "   5.29572516e-01  2.57661526e-02 -1.19904087e-14  1.52644935e-01\n",
            "   7.35089073e-17  3.45500683e-02  1.66533454e-15  3.45279361e-14\n",
            "   1.00000000e+00  2.37556119e-01  5.85594378e-04  1.12238923e-01\n",
            "   1.85438220e-02  5.62365801e-01  3.68924458e-02  3.18172946e-02\n",
            "   1.36443490e-01  1.95198126e-04  4.06012102e-02  1.83681437e-01\n",
            "   9.95510443e-03  9.17431193e-03  1.46398595e-02  5.77786453e-02\n",
            "   2.14717939e-03  3.55650986e-01  1.52254538e-02  1.09115752e-01\n",
            "   5.50458716e-02  1.03455007e-02  1.08801856e-14  5.66660160e-01\n",
            "   2.12765957e-02  1.54792114e-01  1.48936170e-01  1.08334960e-01\n",
            "   8.00312317e-03  4.50907671e-02  8.66679680e-02  5.66074566e-03\n",
            "   8.54577396e-01  5.89498341e-01  4.10501659e-01  9.11575249e-01\n",
            "   8.84247511e-02  9.50419676e-01  4.95803240e-02  6.82022253e-01\n",
            "   3.17977747e-01  3.90396252e-04  3.51356627e-03  3.12317002e-03\n",
            "   1.95198126e-03  3.90396252e-03  9.75990630e-04  3.90396252e-04\n",
            "   5.85594378e-04  4.29435877e-03  1.95198126e-03  7.02713254e-03\n",
            "   1.95198126e-04  1.95198126e-04  1.17118876e-03  6.09863722e-19\n",
            "   3.90396252e-04  7.80792504e-04  7.80792504e-04  3.70876440e-03\n",
            "   2.34237751e-03  9.75990630e-04  1.36638688e-03  2.34237751e-03\n",
            "   1.95198126e-03  3.90396252e-04  4.68475503e-03  3.90396252e-04\n",
            "   7.80792504e-04  7.80792504e-04  1.05406988e-02  2.53757564e-03\n",
            "   5.85594378e-04  1.75678313e-03  3.90396252e-04  3.51356627e-03\n",
            "   3.31836814e-03  1.36638688e-03  3.90396252e-04  9.22506344e-01\n",
            "   1.75678313e-03  9.75781955e-18]\n",
            " [ 2.50573394e-01  7.49426606e-01  3.86085627e-02  6.61314985e-02\n",
            "   7.65099388e-01  2.10244648e-02  6.65137615e-02  4.16666667e-02\n",
            "   9.55657492e-04  5.99388379e-01  4.00611621e-01  3.72706422e-02\n",
            "   3.82262997e-02  1.28058104e-02  7.64525994e-03  1.41437309e-02\n",
            "   3.07721713e-02  2.35091743e-02  2.10244648e-03  2.29357798e-03\n",
            "  -1.12965193e-14 -2.61943245e-16  5.15672783e-01  3.78863607e-15\n",
            "   2.29357798e-03 -5.44703171e-16  3.13264526e-01  9.95603976e-01\n",
            "   4.39602446e-03  4.76681957e-01  1.14678899e-03  1.68195719e-01\n",
            "   3.44036697e-02  8.92584098e-02  1.06077982e-01  1.24235474e-01\n",
            "   2.57454128e-01  7.86046575e-18  7.54969419e-02  1.10282875e-01\n",
            "   2.04510703e-02  2.69495413e-02  8.88761468e-02  1.86544343e-01\n",
            "   1.52905199e-02  4.09021407e-02  1.24235474e-02  1.04931193e-01\n",
            "   2.40825688e-02  3.63149847e-02  1.09356968e-14  4.03096330e-01\n",
            "   4.12844037e-02  4.52981651e-02  3.49197248e-01  1.61123853e-01\n",
            "   1.35703364e-02  2.08333333e-02  1.58256881e-01  8.40978593e-03\n",
            "   7.98929664e-01  7.89373089e-01  2.10626911e-01  9.43233945e-01\n",
            "   5.67660550e-02  9.68463303e-01  3.15366972e-02  8.13073394e-01\n",
            "   1.86926606e-01  1.91131498e-04  4.77828746e-03  2.29357798e-03\n",
            "   3.05810398e-03  4.58715596e-03  4.39602446e-03  1.14678899e-03\n",
            "   3.44036697e-03  3.05810398e-03  9.55657492e-04  3.82262997e-03\n",
            "   7.64525994e-04  2.29357798e-03  3.05810398e-03  6.97955149e-19\n",
            "   7.64525994e-04  3.82262997e-04  5.73394495e-04  5.73394495e-04\n",
            "   5.73394495e-04  5.73394495e-04  3.05810398e-03  3.05810398e-03\n",
            "   1.72018349e-03  7.64525994e-04  1.52905199e-02  9.55657492e-04\n",
            "   7.64525994e-04  1.72018349e-03  4.20489297e-03  1.91131498e-03\n",
            "   2.29357798e-03  7.45412844e-03  9.55657492e-04  2.29357798e-03\n",
            "   1.91131498e-04  5.73394495e-04  1.33792049e-03  9.08256881e-01\n",
            "   1.52905199e-03  3.82262997e-04]\n",
            " [ 3.53115100e-01  6.46884900e-01  4.30834213e-02  8.51108765e-02\n",
            "   6.15628300e-01  8.29989440e-02  1.11087645e-01  6.18796199e-02\n",
            "   2.11193242e-04  5.84371700e-01  4.15628300e-01 -1.14491749e-15\n",
            "  -9.02056208e-16 -3.05311332e-16  1.41379963e-16  2.28983499e-16\n",
            "   1.63064007e-16 -4.44089210e-16  7.81414995e-02  1.23125660e-01\n",
            "   4.92291447e-01  5.13199578e-02 -1.14352972e-14  1.78035903e-01\n",
            "   6.46184495e-17  7.70855333e-02 -2.47024623e-15  2.93098879e-14\n",
            "   1.00000000e+00  2.11193242e-03  6.33579725e-04  9.94931362e-01\n",
            "   8.44772967e-04 -1.64313008e-14  8.44772967e-04  6.33579725e-04\n",
            "   4.60401267e-02  2.11193242e-04  8.36325238e-02  2.69904963e-01\n",
            "   2.25976769e-02  1.07708553e-02  1.81626188e-02  1.60506864e-02\n",
            "   2.11193242e-04  3.18690602e-01  2.53431890e-02  1.33262936e-01\n",
            "   3.82259768e-02  1.68954593e-02  9.87961985e-01  8.44772967e-04\n",
            "   4.22386484e-03  1.90073918e-03  3.59028511e-03  1.47835269e-03\n",
            "   2.32312566e-03  4.75184794e-02  3.16789863e-02  3.80147835e-03\n",
            "   9.14677930e-01  1.26715945e-03  9.98732841e-01  8.29144667e-01\n",
            "   1.70855333e-01  9.11087645e-01  8.89123548e-02  4.86166843e-01\n",
            "   5.13833157e-01  2.11193242e-04  5.70221753e-03  5.06863780e-03\n",
            "   1.26715945e-03  2.53431890e-03  2.11193242e-04  8.44772967e-04\n",
            "   1.90073918e-03  4.85744456e-03  1.90073918e-03  5.70221753e-03\n",
            "   1.90073918e-03  2.11193242e-04  4.22386484e-04  2.77826807e-19\n",
            "  -2.50992803e-17  1.47835269e-03  4.22386484e-04  1.16156283e-02\n",
            "   3.80147835e-03  6.33579725e-04  2.95670539e-03  1.47835269e-03\n",
            "   4.43505808e-03  4.22386484e-04  4.64625132e-03  6.33579725e-04\n",
            "  -9.75781955e-19  4.22386484e-04  9.92608237e-03  1.47835269e-03\n",
            "   6.33579725e-04  1.68954593e-03  2.11193242e-04  3.37909187e-03\n",
            "   4.01267159e-03  2.11193242e-04  1.43114687e-17  9.09609293e-01\n",
            "   1.68954593e-03  1.47835269e-03]]\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Centroids for k=10:\n",
            "[[ 6.77236045e-15  1.00000000e+00  3.42836521e-02 ...  9.47311440e-01\n",
            "   1.44352219e-03  3.60880549e-04]\n",
            " [ 1.00000000e+00 -6.77236045e-15  1.72413793e-02 ...  9.02093596e-01\n",
            "   1.53940887e-03  6.15763547e-04]\n",
            " [ 1.80072029e-03  9.98199280e-01  4.26170468e-02 ...  8.81752701e-01\n",
            "   6.00240096e-04  7.04731412e-18]\n",
            " ...\n",
            " [ 1.19521912e-03  9.98804781e-01  4.06374502e-02 ...  9.25099602e-01\n",
            "   2.39043825e-03  7.96812749e-04]\n",
            " [ 5.77315973e-15  1.00000000e+00  3.72771475e-02 ...  8.95732037e-01\n",
            "   1.62074554e-03  5.40248514e-04]\n",
            " [ 5.76910462e-01  4.23089538e-01  3.64053788e-02 ...  9.20957691e-01\n",
            "   9.83929157e-04 -8.34835673e-18]]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Define the column names based on the dataset description\n",
        "columns = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
        "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
        "    \"hours-per-week\", \"native-country\", \"income\"\n",
        "]\n",
        "\n",
        "# Load the datasets\n",
        "train_data_path = '/content/drive/MyDrive/Data Mining project1/adult.data' # Update with the actual path\n",
        "test_data_path = '/content/drive/MyDrive/Data Mining project1/adult.test' # Update with the actual path\n",
        "\n",
        "train_df = pd.read_csv(train_data_path, names=columns, sep=',\\s', na_values=\"?\", engine='python').dropna()\n",
        "test_df = pd.read_csv(test_data_path, names=columns, sep=',\\s', na_values=\"?\", skiprows=1, engine='python').dropna()\n",
        "\n",
        "# Fix the labels in the test dataset if necessary\n",
        "train_df['income'] = train_df['income'].str.replace('.', '', regex=False)\n",
        "test_df['income'] = test_df['income'].str.replace('.', '', regex=False)\n",
        "\n",
        "# Identify continuous attributes to be converted into binary\n",
        "continuous_columns = [\"age\", \"fnlwgt\", \"education-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
        "\n",
        "# Convert numerical attributes to binary based on their mean\n",
        "for col in continuous_columns:\n",
        "    train_mean = train_df[col].mean()\n",
        "    train_df[col] = (train_df[col] > train_mean).astype(int)\n",
        "\n",
        "# Prepare data for modeling (exclude target variable and reapply one-hot encoding)\n",
        "X_train = train_df.drop('income', axis=1)\n",
        "\n",
        "# Apply one-hot encoding\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "onehot_encoder.fit(X_train)\n",
        "X_train_encoded = onehot_encoder.transform(X_train)\n",
        "\n",
        "# Apply k-means clustering with different values of k\n",
        "k_values = [3, 5, 10]\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_train_encoded)\n",
        "\n",
        "    # Report the centroids of the clusters\n",
        "    print(f'Centroids for k={k}:')\n",
        "    print(kmeans.cluster_centers_)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o-5itgWowdnh",
        "outputId": "0f72fce6-52f2-4b52-acec-e404072b28cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Classifier Evaluation:\n",
            "Accuracy: 0.8738\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "adult = fetch_openml(name='adult', version=2, parser='auto')\n",
        "\n",
        "# Convert to pandas DataFrame and prepare 'X' and 'y'\n",
        "X = pd.DataFrame(adult.data, columns=adult.feature_names)\n",
        "y = pd.Series(adult.target).apply(lambda x: \">50K\" if x.strip() == \">50K\" else \"<=50K\")\n",
        "\n",
        "# Assuming the preprocessing (handling missing values, etc.) is already done\n",
        "\n",
        "# Define the preprocessor\n",
        "categorical_features = X.columns.tolist()\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "    ])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a function to convert a sparse matrix to a dense matrix\n",
        "def to_dense(X):\n",
        "    return X.toarray()\n",
        "\n",
        "# Build the SVM classifier pipeline\n",
        "svm_pipeline = make_pipeline(\n",
        "    preprocessor,\n",
        "    FunctionTransformer(to_dense, accept_sparse=True),  # Convert sparse matrix to dense\n",
        "    SVC(random_state=42)\n",
        ")\n",
        "\n",
        "# Train the SVM classifier on the training data\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_svm = svm_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the SVM classifier\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"SVM Classifier Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_svm:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h7c1gPzzkY3"
      },
      "source": [
        " 4. Continue using the train datasets from step 2, build a neural network classifier and report the predicted accuracy of the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91WU7-6ezmik",
        "outputId": "60f2af3d-45c3-4e90-ac6a-181a14cfa44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network Classifier Accuracy on Test Data: 85.04%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load the dataset\n",
        "adult = fetch_openml(name='adult', version=2, parser='auto')\n",
        "\n",
        "# Convert to pandas DataFrame and prepare 'X' and 'y'\n",
        "X = pd.DataFrame(adult.data, columns=adult.feature_names)\n",
        "y = pd.Series(adult.target).apply(lambda x: \">50K\" if x.strip() == \">50K\" else \"<=50K\")\n",
        "\n",
        "# Assuming the preprocessing (handling missing values, etc.) is already done\n",
        "\n",
        "# Define the preprocessor\n",
        "categorical_features = X.columns.tolist()\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "    ])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the MLPClassifier: Using a single hidden layer with 50 neurons as a starting point\n",
        "nn_classifier = MLPClassifier(hidden_layer_sizes=(50,), max_iter=300, random_state=42)\n",
        "\n",
        "# Apply one-hot encoding through the preprocessor to avoid future errors\n",
        "X_train_encoded = preprocessor.fit_transform(X_train)\n",
        "X_test_encoded = preprocessor.transform(X_test)\n",
        "\n",
        "# Train the neural network classifier on the training data\n",
        "nn_classifier.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred_nn = nn_classifier.predict(X_test_encoded)\n",
        "\n",
        "# Calculate the accuracy of the predictions\n",
        "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f'Neural Network Classifier Accuracy on Test Data: {accuracy_nn * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJxwaoJQciuJ"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}